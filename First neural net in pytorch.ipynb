{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is intended to go with [this blog article](https://sgugger.github.io/a-neural-net-in-pytorch.html) which explains the theory behind it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#pytorch packages \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "#To download the dataset for torchvision\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "#For plots\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and look at the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example, we will try to recognize hand-written digits, specifically the ones of the MNIST dataset, that contains overall 70,000 28-by-28-pixels pictures of hand-written digits. This dataset is easily accessible in pytorch via dataset.MNSIT. You just have to specify you want to download it if it's not already in the directory, and pytorch will process it to create a DataSet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change to the directory of your choice.\n",
    "PATH = '.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grab the training and the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_set = datasets.MNIST(PATH, train=True, download=True)\n",
    "tst_set = datasets.MNIST(PATH, train=False, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the data in the training set first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trn_set.train_data), len(tst_set.test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each image is represented by a tensor of size 28 by 28, each value represents the color of the corresponding pixel, from 0 (black) to 255 (white). Torch tensors are the equivalent of numpy ndarrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\n",
       "Columns 0 to 12 \n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     3\n",
       "    0     0     0     0     0     0     0     0    30    36    94   154   170\n",
       "    0     0     0     0     0     0     0    49   238   253   253   253   253\n",
       "    0     0     0     0     0     0     0    18   219   253   253   253   253\n",
       "    0     0     0     0     0     0     0     0    80   156   107   253   253\n",
       "    0     0     0     0     0     0     0     0     0    14     1   154   253\n",
       "    0     0     0     0     0     0     0     0     0     0     0   139   253\n",
       "    0     0     0     0     0     0     0     0     0     0     0    11   190\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0    35\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0    39\n",
       "    0     0     0     0     0     0     0     0     0     0    24   114   221\n",
       "    0     0     0     0     0     0     0     0    23    66   213   253   253\n",
       "    0     0     0     0     0     0    18   171   219   253   253   253   253\n",
       "    0     0     0     0    55   172   226   253   253   253   253   244   133\n",
       "    0     0     0     0   136   253   253   253   212   135   132    16     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "\n",
       "Columns 13 to 25 \n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "   18    18    18   126   136   175    26   166   255   247   127     0     0\n",
       "  253   253   253   253   253   225   172   253   242   195    64     0     0\n",
       "  253   253   253   253   251    93    82    82    56    39     0     0     0\n",
       "  253   198   182   247   241     0     0     0     0     0     0     0     0\n",
       "  205    11     0    43   154     0     0     0     0     0     0     0     0\n",
       "   90     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "  190     2     0     0     0     0     0     0     0     0     0     0     0\n",
       "  253    70     0     0     0     0     0     0     0     0     0     0     0\n",
       "  241   225   160   108     1     0     0     0     0     0     0     0     0\n",
       "   81   240   253   253   119    25     0     0     0     0     0     0     0\n",
       "    0    45   186   253   253   150    27     0     0     0     0     0     0\n",
       "    0     0    16    93   252   253   187     0     0     0     0     0     0\n",
       "    0     0     0     0   249   253   249    64     0     0     0     0     0\n",
       "    0    46   130   183   253   253   207     2     0     0     0     0     0\n",
       "  148   229   253   253   253   250   182     0     0     0     0     0     0\n",
       "  253   253   253   253   201    78     0     0     0     0     0     0     0\n",
       "  253   253   198    81     2     0     0     0     0     0     0     0     0\n",
       "  195    80     9     0     0     0     0     0     0     0     0     0     0\n",
       "   11     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "\n",
       "Columns 26 to 27 \n",
       "    0     0\n",
       "    0     0\n",
       "    0     0\n",
       "    0     0\n",
       "    0     0\n",
       "    0     0\n",
       "    0     0\n",
       "    0     0\n",
       "    0     0\n",
       "    0     0\n",
       "    0     0\n",
       "    0     0\n",
       "    0     0\n",
       "    0     0\n",
       "    0     0\n",
       "    0     0\n",
       "    0     0\n",
       "    0     0\n",
       "    0     0\n",
       "    0     0\n",
       "    0     0\n",
       "    0     0\n",
       "    0     0\n",
       "    0     0\n",
       "    0     0\n",
       "    0     0\n",
       "    0     0\n",
       "    0     0\n",
       "[torch.ByteTensor of size 28x28]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_set.train_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's easy to convert a torch tensor to a numpy array via the .numpy() command.\n",
    "\n",
    "Conversely, you can create a torch Tensor from a numpy array x via torch.Tensor(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_set.train_data[0].numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's then easy to see the corresponding picture via plt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23085107240>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x23081997cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(trn_set.train_data[0].numpy(), cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the corresponding label..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_set.train_labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pytorch neural network will expect the data to come in the form of minibatches of tensors. To do that, we use a pytorch object called DataLoader. It will randomly separate the pictures (with the associated label) in minibatches. If you have multiple GPUs, it also prepares the work to be parallelized between them (just change num_workers from 0 to your custom value). We only shuffle the data randomly for the training.\n",
    "\n",
    "First we need to explicitely ask our dataset to transform the images in tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsfms = transforms.ToTensor()\n",
    "trn_set = datasets.MNIST(PATH, train=True, download=True, transform=tsfms)\n",
    "tst_set = datasets.MNIST(PATH, train=False, download=True, transform=tsfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_loader = torch.utils.data.DataLoader(trn_set, batch_size=64, shuffle=True, num_workers=0)\n",
    "tst_loader = torch.utils.data.DataLoader(tst_set, batch_size=64, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at an example. A data loader can be converted into an iterator and we can then ask him for a minibatch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mb_example = next(iter(trn_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Such a minibacth containts two torch tensors: the first one contains the data (here our pictures) and the second one the expected labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 1, 28, 28]), torch.Size([64]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mb_example[0].size(), mb_example[1].size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that pytorch has automatically added one dimension to our images (the 1 in second position). It would be 3 if we had had the three usual channels for the colors (RGB). Pytorch puts this channel in the second dimension and not the last because it simplifies some computation.\n",
    "\n",
    "Let's see the first tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\n",
       "Columns 0 to 9 \n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0667  0.9059\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0118  0.6824  0.9961\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0941  0.9922  0.9961\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0353  0.8235  1.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.3294  0.9961\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.7961\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0745\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "\n",
       "Columns 10 to 19 \n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.4471  0.7961  0.9961  0.9961  0.7961  0.4706  0.0745  0.0000  0.0000  0.0000\n",
       " 0.9843  0.9922  0.8588  0.4510  0.6471  0.9569  0.7961  0.4000  0.0000  0.0000\n",
       " 0.5098  0.1804  0.0510  0.0000  0.0000  0.1490  0.4431  0.8549  0.0667  0.0000\n",
       " 0.0902  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.1882  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.8784  0.0980  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.9922  0.6392  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0196  0.6824\n",
       " 0.9255  0.9647  0.4627  0.0000  0.0000  0.0000  0.0000  0.3333  0.7725  0.6588\n",
       " 0.2000  0.8824  0.9961  0.5333  0.0275  0.1255  0.6667  0.9255  0.6549  0.0667\n",
       " 0.0000  0.1059  0.7765  0.9961  0.7804  0.9451  0.9255  0.1961  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0667  0.8627  0.9922  0.9922  0.3686  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.4000  0.9961  0.8588  0.9922  0.7608  0.1333  0.0000  0.0000\n",
       " 0.0000  0.4235  0.9961  0.4980  0.0000  0.4902  0.9961  0.8980  0.1569  0.0000\n",
       " 0.1686  0.9098  0.7255  0.0353  0.0000  0.0118  0.3529  0.9961  0.8784  0.3647\n",
       " 0.8392  0.9490  0.1490  0.0000  0.0000  0.0000  0.0000  0.5333  0.9922  0.9412\n",
       " 0.9020  0.9020  0.0000  0.0000  0.0000  0.0000  0.0000  0.0745  0.5294  0.9922\n",
       " 0.9059  0.9294  0.0745  0.0000  0.0000  0.0000  0.0000  0.0000  0.0667  0.8824\n",
       " 0.3451  0.9569  0.6627  0.0667  0.0000  0.0000  0.0000  0.0000  0.1020  0.9098\n",
       " 0.0000  0.4784  0.9647  0.8824  0.6157  0.4549  0.4549  0.6824  0.8471  0.9176\n",
       " 0.0000  0.0000  0.1961  0.8627  0.9922  0.9922  0.9922  0.9961  0.9255  0.2118\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "\n",
       "Columns 20 to 27 \n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0667  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.8784  0.5255  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.2706  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.1569  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.6275  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.8627  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.9255  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.2118  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "[torch.FloatTensor of size 28x28]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mb_example[0][0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that pytorch transformed the values that went from 0 to 255 into floats that go from 0. to 1.\n",
    "\n",
    "We can have a look at the first pictures and draw them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x230851494e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "for i in range(0,4):\n",
    "    sub_plot = fig.add_subplot(1,4,i+1)\n",
    "    sub_plot.axis('Off')\n",
    "    plt.imshow(mb_example[0][i,0].numpy(), cmap='Greys')\n",
    "    sub_plot.set_title(mb_example[1][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another usual transformation we do before feeing the pictures to our neural network is to normalize the input. This means subtracting the mean and dividing by the standard deviation. We can either search for the usual values on Google or compute them from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1306604762738429, 0.30810780717887876)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = torch.mean(trn_set.train_data.type(torch.FloatTensor))/255.\n",
    "std = torch.std(trn_set.train_data.type(torch.FloatTensor))/255.\n",
    "mean,std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We divide by 255 to get the means of our data when it's convereted into floats from 0. to 1.\n",
    "\n",
    "Then we go back to creating a transfrom and add the normalization. Note that we use the same mean and std for the test set. Afterward, we reload our datasets, adding this transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsfms = transforms.Compose([transforms.ToTensor(), transforms.Normalize((mean,), (std,))])\n",
    "trn_set = datasets.MNIST(PATH, train=True, download=True, transform=tsfms)\n",
    "tst_set = datasets.MNIST(PATH, train=False, download=True, transform=tsfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_loader = torch.utils.data.DataLoader(trn_set, batch_size=64, shuffle=True, num_workers=0)\n",
    "tst_loader = torch.utils.data.DataLoader(tst_set, batch_size=64, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if we want to plot our digits, we will have to denormalize the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mb_example = next(iter(trn_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x230847420f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "for i in range(0,4):\n",
    "    sub_plot = fig.add_subplot(1,4,i+1)\n",
    "    sub_plot.axis('Off')\n",
    "    plt.imshow(mb_example[0][i,0].numpy() * std + mean, cmap='Greys', interpolation=None)\n",
    "    sub_plot.set_title(mb_example[1][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's always a good idea to create a model as a subclass of nn.Module. That way, we can use all the features this class provides.\n",
    "\n",
    "We override the init function (but still call the init function of nn.Module) to define our custom layers (here two linear layers) and we have to define the forward function, which explains how to compute the output.\n",
    "\n",
    "The first line of the forward function is to flatten our input, since we saw it has four dimensions: minibatch by channel by height by width. We only keep the minibatch size as our first dimension (x.size(0)) and the -1 is to tell pytorch to determine the right number for the second dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNeuralNet(nn.Module):\n",
    "    def __init__(self, n_in, n_hidden, n_out):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(n_in, n_hidden)\n",
    "        self.linear2 = nn.Linear(n_hidden, n_out)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = F.relu(self.linear1(x))\n",
    "        return F.log_softmax(self.linear2(x), dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can instanciate the class with our input size (28 * 28), an hidden size of 100 layers and 10 outputs (as many as digits).\n",
    "\n",
    "The optimizer will automatically do the Stochastic Gradient Descent for us (or any of its variant if we want)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SimpleNeuralNet(28*28,100,10)\n",
    "optimizer = optim.SGD(net.parameters(),lr=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to write our training loop. To compute the gradient automatically, pytorch requires us to put the torch tensors with our inputs and labels into Variable objects, that way it'll remember the transformation these go through until we arrive at our loss function. We then call loss.backward() to compute all the gradients (which will then be in the grad field of any variable).\n",
    "\n",
    "The optimizer takes care of the step of our gradient descent in the optimizer.step() function. Since the gradients are accumulated, we have to tell pytorch when to reinitialize them (which the purpose of the optimizer.zero_grad() command at the beginning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(nb_epoch):\n",
    "    for epoch in range(nb_epoch):\n",
    "        running_loss = 0.\n",
    "        corrects = 0\n",
    "        print(f'Epoch {epoch+1}:')\n",
    "        for data in trn_loader:\n",
    "            #separate the inputs from the labels\n",
    "            inputs,labels = data\n",
    "            #wrap those into variables to keep track of how they are created and be able to compute their gradient.\n",
    "            inputs, labels = Variable(inputs), Variable(labels)\n",
    "            #Put the gradients back to zero\n",
    "            optimizer.zero_grad()\n",
    "            #Compute the outputs given by our model at this stage.\n",
    "            outputs = net(inputs)\n",
    "            _,preds = torch.max(outputs.data,1)\n",
    "            #Compute the loss\n",
    "            loss = F.nll_loss(outputs, labels)\n",
    "            running_loss += loss.data[0] * inputs.size(0)\n",
    "            corrects += torch.sum(labels.data == preds)\n",
    "            #Backpropagate the computation of the gradients\n",
    "            loss.backward()\n",
    "            #Do the step of the SGD\n",
    "            optimizer.step()\n",
    "        print(f'Loss: {running_loss/len(trn_set)}  Accuracy: {100.*corrects/len(trn_set)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "Loss: 2.316405006790161  Accuracy: 10.841666666666667\n"
     ]
    }
   ],
   "source": [
    "train(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "96.23% accuracy is good, but that's on the training set and we may be overfitting. Let's try on the test set now to see if we're doing well or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate():\n",
    "    running_loss = 0.\n",
    "    corrects = 0\n",
    "    for data in tst_loader:\n",
    "        #separate the inputs from the labels\n",
    "        inputs,labels = data\n",
    "        #wrap those into variables to keep track of how they are created and be able to compute their gradient.\n",
    "        #Even if we don't require the gradient here, a nn.Module expects a variable.\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "        #Compute the outputs given by our model at this stage.\n",
    "        outputs = net(inputs)\n",
    "        _,preds = torch.max(outputs.data,1)\n",
    "        #Compute the loss\n",
    "        loss = F.nll_loss(outputs, labels)\n",
    "        running_loss += loss.data[0] * inputs.size(0)\n",
    "        corrects += torch.sum(labels.data == preds)\n",
    "    print(f'Loss: {running_loss/len(tst_set)}  Accuracy: {100.*corrects/len(tst_set)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we weren't overfitting!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
